spring.application.name=FOOBAR-SpringBatch

# Enable batch jobs to start automatically
spring.batch.job.enabled=false

server.port=9090

spring.main.allow-bean-definition-overriding=true

app.input.dir=${APP_INPUT_DIR:./input}
app.output.dir=${APP_OUTPUT_DIR:./output}



# Use H2 in-memory database for testing
spring.datasource.url=jdbc:h2:mem:testdb
spring.datasource.driver-class-name=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=
spring.h2.console.enabled=true

# Ensure Spring Batch initializes job tables in H2
spring.batch.jdbc.initialize-schema=always

# Kafka
spring.kafka.bootstrap-servers=${DOCKER_KAFKA:localhost:9093}
spring.kafka.consumer.group-id=batch-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#manualy commit offset after job termination
spring.kafka.consumer.enable-auto-commit=false 

# values to change to prevent consumer overhead or optimize performance/throughput/latency:
# Define Max data per partition in one fetch (default 1MB)
spring.kafka.consumer.properties.max.partition.fetch.bytes=524288
# Define Max total data in one fetch across all partitions (default 50MB)
spring.kafka.consumer.properties.fetch.max.bytes=10485760
# Define Minimum data per fetch before broker returns (default 1byte)
spring.kafka.consumer.properties.fetch.min.bytes=1
# Define How long to wait for fetch.min.bytes before returning (default 500ms)
spring.kafka.consumer.fetch-max-wait=1000
# Define Max records returned in one poll (default 500)
spring.kafka.consumer.max-poll-records=100

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer